{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Learning Machines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous entraînerons le réseau à classer les chiffres manuscrits à l'aide de l'ensemble de données MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'importation des packages necessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.linalg import pinv2\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On doit telecharger la dataset pour entrainer notre ELM et tester le modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 28**2\n",
    "num_classes = 10\n",
    "\n",
    "# Load MNIST Dataset \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() \n",
    "# Process images into input vectors \n",
    "# each mnist image is a 28x28 picture with value ranges between 0 and 255 \n",
    "x_train = x_train.astype(np.float32) / 255. \n",
    "x_train = x_train.reshape(-1, input_length) \n",
    "x_test = x_test.astype(np.float32) / 255. \n",
    "x_test = x_test.reshape(-1, input_length) \n",
    "# converts [1,2] into [[0,1,0], [0,0,1]] \n",
    "y_train = to_categorical(y_train, num_classes).astype(np.float32) \n",
    "y_test = to_categorical(y_test, num_classes).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour initialiser notre reseaux, nous sommes besoin d'identifier:\n",
    "1. La taille de la couche d'entrée, qui correspond au nombre des valeurs d'entrée\n",
    "2. Le nombre des noeuds cachées\n",
    "3. L'entrée des poids cachées\n",
    "4. Fonction d'activation de la couche cachée\n",
    "\n",
    "La taille de la couche d'entrée fait référence au nombre de valeurs en entrée du jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisons le nombre de neurones cachés à 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous devons initialiser les poids d'entrée et les biais tirés au hasard d'une distribution gaussienne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_weights = np.random.normal(size=[input_size,hidden_size])\n",
    "biases = np.random.normal(size=[hidden_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction d'activation de la couche cachée (Nous utiliserons une unité linéaire rectifiée (ReLU) comme fonction d'activation de couche cachée)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x, 0, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons une fonction pour calculer notre vecteur H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_nodes(X):\n",
    "    G = np.dot(X, input_weights)\n",
    "    G = G + biases\n",
    "    H = relu(G)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculer notre β(output_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_weights = np.dot(pinv2(hidden_nodes(x_train)), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour s'assurer que notre modèle produit un bon résultat, nous devons d'abord le tester. Créons une fonction pour gérer les tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    out = hidden_nodes(X)\n",
    "    out = np.dot(out, output_weights)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for  1000  hidden nodes:  0.9421\n"
     ]
    }
   ],
   "source": [
    "prediction = predict(x_test)\n",
    "correct = 0\n",
    "total = x_test.shape[0]\n",
    "\n",
    "\n",
    "for i in range(total):\n",
    "    predicted = np.argmax(prediction[i])\n",
    "    actual = np.argmax(y_test[i])\n",
    "    correct += 1 if predicted == actual else 0\n",
    "accuracy = correct/total\n",
    "print('Accuracy for ', hidden_size, ' hidden nodes: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La précision du modèle est de 0.9421, ce qui est déjà un bon résultat compte tenu du fait que nous n'avons qu'une seule couche cachée avec 1000 nœuds cachés et un réglage non itératif pour l'apprentissage, ce qui le rend plus rapide que toutes les techniques basées sur le gradient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
